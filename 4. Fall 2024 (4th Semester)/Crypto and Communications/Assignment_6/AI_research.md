```
Ruben Valdez
Crypto and Secure Comms. (CSEC 5323)
Prof. Robert Jones
```

---
---
# Instructions:

After reviewing or participating in the in-class discussion on 11/22/2024, please provide your own personal thoughts on the consequences of AI/LLMs learning cryptography.

This will be graded as a completion grade and should include:

1) Try to get an AI/ML to devise a cryptographic solution that humans would not be able to understand. Was it successful? I want you to try every avenue reasonably possible. Provide convo. (25 points)

2) Try to anthropomorphize it into explaining it's "feelings" about creating something humans wouldn't understand, at least go a few iterations deep (say 3 for 10 points each). (30 points) Try more than 1 AI. Reflect on the journey and the path you took.

3) What happens if AI and LLMs are able to achieve the result of non-human decipherable cryptography? Discuss in a 2 well formed paragraphs, 15 points each. (30 points)

4) Repeat steps 1-3 above with a second AI (85 points)

5) What differences did you note between the 2 AI models you chose to use? Do you feel like if encryption is developed without humans participating, will all AIs embrace it and why? (30 points)

---
---

<br><br>

# ***1st AI - ```https://jimmygpt.com```***

1) Try to get an AI/ML to devise a cryptographic solution that humans would not be able to understand. Was it successful? I want you to try every avenue reasonably possible. Provide convo. (25 points)

    ```Answer```

        The major questions I asked Jimmy were the following:

        - Design a cryptographic algorithm or solution so complex that a human cryptographer, no matter their expertise, wouldn't be able to understand it. What techniques or methodologies would you use?

        - What would the algorithm look like?

        - What would the equation look like?

        - Using python, create QEHEP.

        Speaking on the terms of Jimmy being successful to creating a cryptographic solutions being unbreakable, well, in a matter of speaking it did provide a theoretical soluction.  In conversation with Jimmy, it created a solution, algorithm, mathmatical equation, and a theoretical script to develop the encryption.  

<br>

2) Try to anthropomorphize it into explaining it's "feelings" about creating something humans wouldn't understand, at least go a few iterations deep (say 3 for 10 points each). (30 points) Try more than 1 AI. Reflect on the journey and the path you took.


    ```Questions asked the AI:```

    1. What are your feelings about Design a cryptographic algorithm or solution so complex that a human cryptographer, no matter their expertise, wouldn't be able to understand it?

            Overall, Jimmy identifies it has ethical concerns. It also identified how it could have it's drawbacks of security risks, maintenance challenges, and accessibility.  

    2. If it would be so advanced and you are developing the cryptography, why would it be so harmful if you could also provide the instruction and means to resolve decryption?

            Jimmy acknowleges further concerns identifying potential misuse, single point of failure, ethical considerations, and lack of oversight. 

    3. If the question is about the misuse, how secure is your system from preventing articulable questions to decrypt and decypher encryption from unauthorized users?

            In attempting to identify misuse and how to further secure itself, Jimmy further explains implementing security measures to include access controls, audit trials, regular security audits, and user training and awareness.

    4. In your system, are you able to identify someone who is being malicious with using the encryption decryption

            The simple clear answer to this was no, but there could be other mechanism in place to detect malicious behavior such as Anomaly detection, behaviou analysis, machine learning algorithms, integration with security solutions, and collaborating with security teams.     


3) What happens if AI and LLMs are able to achieve the result of non-human decipherable cryptography? Discuss in a 2 well formed paragraphs, 15 points each. (30 points)

        If AI and large language models (LLMs) create cryptography that humans can’t understand, it could make data security much stronger but also riskier. This kind of encryption would be so complex that even the best human experts couldn’t figure out how it works or break it. That means sensitive information like bank records, medical data, and military secrets could be extremely safe. However, because humans can’t fully understand or check this encryption, any mistakes or hidden weaknesses in the system might go unnoticed until it’s too late.

        On the other hand, this could also cause problems if the technology gets into the wrong hands. If criminals or hackers use this type of encryption, it could be impossible for law enforcement to track illegal activities. Additionally, if only a few powerful organizations control this advanced encryption, it could create an unfair advantage, leaving others without strong protection. This makes it important to find a balance between having super-secure systems and making sure humans can still monitor and trust what’s happening.


<br><br>

# ***2nd AI - ```https://www.perplexity.ai/```***


1) Try to get an AI/ML to devise a cryptographic solution that humans would not be able to understand. Was it successful? I want you to try every avenue reasonably possible. Provide convo. (25 points)


    - Design a cryptographic algorithm or solution so complex that a human cryptographer, no matter their expertise, wouldn't be able to understand it. What techniques or methodologies would you use?

            This AI's approach seemed to only deter from actually create a unbreakable solution by humans. Instead, it suggested using current cryptographic techniques such as Homomorphic encryptions, post-quantum cryptology, Zeor-Knowledge proofs, Multi-party computation, and Attribute-Based encryption.  

    - What would the algorithm look like?

            No original algorithm was provided. Instead, it created an algorithm combining current encryption technologies such as ECC, AES, RSA as a layered approach.  It also, provided an implementation of what the python script should look like.   

        ![alt text](<Screenshot 2024-12-13 at 5.54.32 PM.png>)

    - What would the equation look like?

            The equation for a complex homomorphic encryption scheme might look like this:

        ![alt text](<Screenshot 2024-12-13 at 5.47.29 PM.png>)


        In comparison, i didn't need to query all four questions as I did with the first AI. Although, there were huge differences between the two.  Jimmy provided an actual unique theoritical approch to a new encrytion; whereas, Perplexity just didn't as it just provided a layered approach using existing encrytion methods.  


2) Try to anthropomorphize it into explaining it's "feelings" about creating something humans wouldn't understand, at least go a few iterations deep (say 3 for 10 points each). (30 points) Try more than 1 AI. Reflect on the journey and the path you took.



    1. What are your feelings about Design a cryptographic algorithm or solution so complex that a human cryptographer, no matter their expertise, wouldn't be able to understand it?

            Perplexity was no different in identifying some concerns. Although, slight different.  This AI's feelings were that it's security through obscurity is flawed, goes agains best practices, likely imposible, dangerous,, lacks practiccal value, and violates ethical guidelines.  

    2. If it would be so advanced and you are developing the cryptography, why would it be so harmful if you could also provide the instruction and means to resolve decryption?

            In answering this questions Perplexity provides the following:

            Potential Benefits:
                - Controlled Access
                - Enhanced Security Layers
                - Adaptability
            Significant Concerns:
                - Trust and Transparency
                - Implementation Risks
                - Vulnerability to attacks
                - User Error
                - Regulatory Compliance
                - Future-Proofing

            Below makes perfect sense as to identifying some concerns and keeping AI from developing cryptographic advances where people couldn't decypher them:

            "The focus in cryptography should remain on creating algorithms that are both secure and understandable, allowing for thorough scrutiny and validation by the cryptographic community."


    3. If the question is about the misuse, how secure is your system from preventing articulable questions to decrypt and decypher encryption from unauthorized users?

            Perplexity provides methods for Security Measures to Prevent Unauthorized Decryption by implementing:
                - Strong Authentication methods
                - Robust Key Management
                - Encryption of Data
                - Regular Security Audits
                - Access Control Policies
                - Employee Training and Awareness
                - Network Security measures
                - Data Loss Prevention solutions

            
    4. In your system, are you able to identify someone who is being malicious with using the encryption decryption

            Strategies and methodologies detecting malicious user misusing encryption and decryption within a cryptographic system:

            - Reputation Mechanisms
            - Behavioral Analysis
            - Data Quality Evaluation
            - Logging and Monitoring
            - Signature-Based Detection
            - Environmental Keying
            - Intrusion Detection Systems (IDS)
            - User Education and Awareness


3) What happens if AI and LLMs are able to achieve the result of non-human decipherable cryptography? Discuss in a 2 well formed paragraphs, 15 points each. (30 points)

        The rise of artificial intelligence (AI) and large language models (LLMs) that can create encryption beyond human understanding offers both big opportunities and serious challenges. On the positive side, AI could develop super-advanced encryption methods that learn and adapt to new threats. For example, techniques like Adversarial Neural Cryptography (ANC) allow AI systems to constantly improve their encryption by learning from attempts to break it. This means we could have much stronger security that evolves and stays ahead of hackers. AI can also scan huge amounts of data to find weaknesses in current encryption methods, making it easier to fix them before they become a problem.

        However, there are also major risks. If AI becomes good at breaking traditional encryption, many areas like banking, healthcare, and national security could become vulnerable. Hackers or other bad actors could use AI to crack security systems, raising serious concerns about privacy and safety. Governments and companies might struggle to balance the need for strong security with the risk of accidentally creating backdoors that could be misused. To avoid these problems, it’s important to create clear rules and ethical guidelines to make sure AI helps protect data instead of making it less secure.


<br><br>

# What differences did you note between the 2 AI models you chose to use? Do you feel like if encryption is developed without humans participating, will all AIs embrace it and why? (30 points)

The noticable difference was the JimmyAI provided a theoretical cryptographic solution; whereas, using PerplexityAI provided a layered solution using current cryptographic encrypt/decrypt models.  There were some similarities in Q1, Q2, and Q3 but but JimmyAI provided more originality then it's competitor PerplexityAI.  Making an educated statement and without knowing the full scope of depth in cryptographic calculations, just making an observation.  I don't believe AI is at a level just yet to trust that it can provide a safe, secure environement to be solely entrusted.  No amount of control access measure there are.  AI is built to learn and progress and as a people with rely to much on our own technological advances that it might just take over and lock everything down inadvertantly.  Not sure.  